{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKVs2DAc5Ha78/YYNbt6wo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor11112/Global-Disaster-Dashboard/blob/main/Raw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv3QueFLY6QM"
      },
      "outputs": [],
      "source": [
        "# üì§ Upload file from local machine\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# üìÑ Load the CSV into a DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Replace this with your uploaded filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(filename, encoding='latin1')\n",
        "\n",
        "# Preview the data\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# üìÖ Convert Start/End parts into full datetime\n",
        "date_parts = ['Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month', 'End Day']\n",
        "df[date_parts] = df[date_parts].fillna(1).astype(int)  # fill NaNs with 1\n",
        "\n",
        "df['Start_Date'] = pd.to_datetime(df[['Start Year', 'Start Month', 'Start Day']].rename(columns={'Start Year': 'year', 'Start Month': 'month', 'Start Day': 'day'}), errors='coerce')\n",
        "df['End_Date'] = pd.to_datetime(df[['End Year', 'End Month', 'End Day']].rename(columns={'End Year': 'year', 'End Month': 'month', 'End Day': 'day'}), errors='coerce')\n",
        "\n",
        "# ‚è±Ô∏è Disaster duration in days\n",
        "df['Disaster_Duration'] = (df['End_Date'] - df['Start_Date']).dt.days\n",
        "df['Disaster_Duration'] = df['Disaster_Duration'].apply(lambda x: x if x >= 0 else np.nan)"
      ],
      "metadata": {
        "id": "lRSHZ4jhZLuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize cost fields by stripping $ and commas\n",
        "cost_cols = [\n",
        "    \"Total Damage ('000 US$)\",\n",
        "    \"Total Damage, Adjusted ('000 US$)\",\n",
        "    \"Reconstruction Costs ('000 US$)\",\n",
        "    \"Reconstruction Costs, Adjusted ('000 US$)\",\n",
        "    \"Insured Damage ('000 US$)\",\n",
        "    \"Insured Damage, Adjusted ('000 US$)\",\n",
        "    \"Aid Contribution ('000 US$)\"\n",
        "]\n",
        "\n",
        "for col in cost_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col].astype(str).str.replace(r'[^\\d.]', '', regex=True), errors='coerce')\n"
      ],
      "metadata": {
        "id": "ZaACRW1qZkfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üî• Visualize missing data\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='plasma')\n",
        "plt.title(\"Missing Data Heatmap\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qhBnoi_jZuyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Admin Units field is JSON-like; parse to extract region names\n",
        "def extract_admin_names(raw):\n",
        "    try:\n",
        "        fixed = raw.replace(\"'\", \"\\\"\")\n",
        "        parsed = json.loads(fixed)\n",
        "        names = [d.get('adm1_name') or d.get('adm2_name') for d in parsed]\n",
        "        return names\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df['Admin_Names'] = df['Admin Units'].apply(extract_admin_names)\n"
      ],
      "metadata": {
        "id": "KMS7fY1GZ14L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Latitude'] = pd.to_numeric(df['Latitude'], errors='coerce')\n",
        "df['Longitude'] = pd.to_numeric(df['Longitude'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "aOoV8vXRZ9Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "WsvDtcVRbgLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Check if all preview columns exist before displaying\n",
        "expected_cols = [\n",
        "    'Start_Date', 'End_Date', 'Disaster_Duration',\n",
        "    'Was_Aid_Provided', 'Damage_Per_Death',\n",
        "    'Has_Missing_Data', 'Admin_Names'\n",
        "]\n",
        "\n",
        "available_cols = [col for col in expected_cols if col in df.columns]\n",
        "\n",
        "# Preview available cleaned data safely\n",
        "df[available_cols].head()\n"
      ],
      "metadata": {
        "id": "_eUjSznrb2B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def extract_admin_names(raw):\n",
        "    try:\n",
        "        fixed = raw.replace(\"'\", \"\\\"\")\n",
        "        parsed = json.loads(fixed)\n",
        "        names = [d.get('adm1_name') or d.get('adm2_name') for d in parsed]\n",
        "        return names\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df['Admin_Names'] = df['Admin Units'].apply(extract_admin_names)\n"
      ],
      "metadata": {
        "id": "68ewf_4Nb_qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set visual style\n",
        "sns.set(style='whitegrid')\n"
      ],
      "metadata": {
        "id": "1KIuPOwOcM3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of disasters per year\n",
        "df_yearly = df['Start_Date'].dt.year.value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.lineplot(x=df_yearly.index, y=df_yearly.values, marker='o')\n",
        "plt.title('üìà Disaster Frequency Over the Years', fontsize=16)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Disasters')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oZSbP7xscOEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count by disaster type\n",
        "top_types = df['Disaster Type'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=top_types.values, y=top_types.index, palette='flare')\n",
        "plt.title('üî• Top 10 Disaster Types by Frequency', fontsize=16)\n",
        "plt.xlabel('Number of Disasters')\n",
        "plt.ylabel('Disaster Type')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wZAyoiJJcbOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Year column\n",
        "df['Start_Year'] = df['Start_Date'].dt.year\n",
        "\n",
        "# Group by Year and Disaster Type\n",
        "df_type_trend = df.groupby(['Start_Year', 'Disaster Type']).size().reset_index(name='Count')\n",
        "\n",
        "# Pivot for plotting\n",
        "pivot = df_type_trend.pivot(index='Start_Year', columns='Disaster Type', values='Count').fillna(0)\n",
        "\n",
        "# Plot trend of top 5 types only\n",
        "top5 = df['Disaster Type'].value_counts().head(5).index\n",
        "pivot[top5].plot(figsize=(14,6), linewidth=2)\n",
        "\n",
        "plt.title('üìä Disaster Type Trends Over Time (Top 5)', fontsize=16)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Disaster Count')\n",
        "plt.legend(title='Disaster Type')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Au4c_21Mcfay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a Month column\n",
        "df['Start_Month'] = df['Start_Date'].dt.month\n",
        "\n",
        "# Group by month\n",
        "monthly_counts = df['Start_Month'].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=monthly_counts.index, y=monthly_counts.values, palette='crest')\n",
        "plt.title('üìÜ Disasters by Month (All Years Combined)', fontsize=16)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Disasters')\n",
        "plt.xticks(ticks=range(0,12), labels=[\n",
        "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
        "])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AuHdAiw7cjuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Country'].unique()[:5]\n"
      ],
      "metadata": {
        "id": "xnkF5UAMcqcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_countries = df['Country'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_countries.values, y=top_countries.index, palette='magma')\n",
        "plt.title('üåç Top 10 Countries by Number of Disasters', fontsize=16)\n",
        "plt.xlabel('Number of Disasters')\n",
        "plt.ylabel('Country')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G1SYEja6c1BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum total deaths per country\n",
        "deadliest = df.groupby('Country')['Total Deaths'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=deadliest.values, y=deadliest.index, palette='Reds_r')\n",
        "plt.title('‚ò†Ô∏è Top 10 Deadliest Countries (by Deaths)', fontsize=16)\n",
        "plt.xlabel('Total Deaths')\n",
        "plt.ylabel('Country')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7oy0A1grc3KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum of adjusted damage per country\n",
        "top_damage = df.groupby('Country')[\"Total Damage, Adjusted ('000 US$)\"].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_damage.values, y=top_damage.index, palette='YlOrBr')\n",
        "plt.title('üí∞ Top 10 Countries by Economic Damage', fontsize=16)\n",
        "plt.xlabel(\"Total Damage (000' USD, Adjusted)\")\n",
        "plt.ylabel('Country')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aMK_ZqpBc76a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how often each region appears\n",
        "admin_flat = df['Admin_Names'].dropna().explode()\n",
        "top_regions = admin_flat.value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_regions.values, y=top_regions.index, palette='PuBuGn')\n",
        "plt.title('üèûÔ∏è Top 10 Affected Regions (Admin Units)', fontsize=16)\n",
        "plt.xlabel('Disaster Events')\n",
        "plt.ylabel('Region')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OEBlm0nac_ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "DU5m04h2dFFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Safely create the column\n",
        "df['Damage_Per_Death'] = df[\"Total Damage, Adjusted ('000 US$)\"] / df['Total Deaths']\n",
        "df['Damage_Per_Death'].replace([np.inf, -np.inf], np.nan, inplace=True)\n"
      ],
      "metadata": {
        "id": "ZtesS8ePfLlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define only the columns that exist\n",
        "corr_features = [\n",
        "    'Total Deaths',\n",
        "    \"Total Damage, Adjusted ('000 US$)\",\n",
        "    \"AID Contribution ('000 US$)\",    # Corrected column name\n",
        "    'Disaster_Duration',\n",
        "    'Damage_Per_Death'\n",
        "]\n",
        "\n",
        "# Drop rows with missing values in those columns\n",
        "corr_df = df[corr_features].dropna()\n",
        "\n",
        "# Compute and plot the correlation matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('üìå Correlation Between Disaster Impact Metrics', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VTNuGMLrfOUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "HqVB31AufZWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing critical values\n",
        "model_df = df[[\n",
        "    'Disaster Type', 'Region', 'Disaster_Duration',\n",
        "    'Total Deaths', \"Total Damage, Adjusted ('000 US$)\"\n",
        "]].dropna()\n",
        "\n",
        "# Features and target\n",
        "X = model_df[['Disaster Type', 'Region', 'Disaster_Duration']]\n",
        "y = model_df[\"Total Damage, Adjusted ('000 US$)\"]  # Change to 'Total Deaths' to switch targets\n"
      ],
      "metadata": {
        "id": "KgDFLXOIfsab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical features\n",
        "X_encoded = pd.get_dummies(X, columns=['Disaster Type', 'Region'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "0R2Fxxi1fvir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "lM_u7A0XfyEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "# Calculate RMSE by taking the square root of the mean squared error\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"üìâ RMSE: {rmse:,.0f}\")\n",
        "print(f\"üìà R¬≤ Score: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "7VlDe7zTf1GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get feature importances\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
        "feat_importances.nlargest(10).sort_values().plot(kind='barh', figsize=(8,5), color='skyblue')\n",
        "plt.title('üß† Top Predictors of Disaster Damage')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WgLAxS_WgOij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "model_df = df[[\n",
        "    'Disaster Type', 'Region', 'Disaster_Duration',\n",
        "    'Total Deaths'\n",
        "]].dropna()\n",
        "\n",
        "X = model_df[['Disaster Type', 'Region', 'Disaster_Duration']]\n",
        "y = model_df['Total Deaths']\n",
        "\n",
        "# One-hot encode\n",
        "X_encoded = pd.get_dummies(X, columns=['Disaster Type', 'Region'], drop_first=True)\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train\n",
        "death_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "death_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = death_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"üìâ RMSE (Deaths): {rmse:,.2f}\")\n",
        "print(f\"üìà R¬≤ Score (Deaths): {r2:.2f}\")"
      ],
      "metadata": {
        "id": "JgToVnrAg3vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_imp = pd.Series(death_model.feature_importances_, index=X_train.columns)\n",
        "feat_imp.nlargest(10).sort_values().plot(kind='barh', figsize=(8,5), color='salmon')\n",
        "plt.title('üîç Top Features Predicting Total Deaths')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W_z0u7iKg-fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set 10 million threshold\n",
        "df['High_Damage'] = df[\"Total Damage, Adjusted ('000 US$)\"] > 10000  # $10M in thousands\n",
        "\n",
        "# Check balance\n",
        "print(df['High_Damage'].value_counts())\n"
      ],
      "metadata": {
        "id": "gB_9PLMYhFhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "class_df = df[[\n",
        "    'Disaster Type', 'Region', 'Disaster_Duration', 'High_Damage'\n",
        "]].dropna()\n",
        "\n",
        "X = class_df[['Disaster Type', 'Region', 'Disaster_Duration']]\n",
        "y = class_df['High_Damage'].astype(int)  # must be 0/1 for classification\n",
        "\n",
        "# One-hot encode\n",
        "X_encoded = pd.get_dummies(X, columns=['Disaster Type', 'Region'], drop_first=True)\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "Z5PVkuMEhIGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Asy7amfAhMZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_imp_class = pd.Series(clf.feature_importances_, index=X_train.columns)\n",
        "feat_imp_class.nlargest(10).sort_values().plot(kind='barh', figsize=(8,5), color='limegreen')\n",
        "plt.title('üìä Top Predictors: Will Damage Exceed $10M?')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ukYNyYSyhSpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly --quiet\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "-cBOuIm2hVtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.treemap(df,\n",
        "                 path=['Disaster Group', 'Disaster Type'],\n",
        "                 title='üß© Distribution of Disaster Types',\n",
        "                 color_discrete_sequence=px.colors.qualitative.Safe)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "-JDmx_Hahtsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from google.colab import files\n",
        "\n",
        "# Create the treemap\n",
        "fig = px.treemap(df,\n",
        "                 path=['Disaster Group', 'Disaster Type'],\n",
        "                 title='üß© Distribution of Disaster Types',\n",
        "                 color_discrete_sequence=px.colors.qualitative.Safe)\n",
        "\n",
        "# Save it to an HTML file\n",
        "fig.write_html(\"disaster_treemap.html\")\n",
        "\n",
        "# Download the HTML file to your computer\n",
        "files.download(\"disaster_treemap.html\")\n"
      ],
      "metadata": {
        "id": "HCRakP081uJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.pie(df,\n",
        "             names='Disaster Type',\n",
        "             title='üåç Proportion of Disaster Types')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "SZceF_3Rh-dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from google.colab import files\n",
        "\n",
        "# Create the interactive pie chart\n",
        "fig = px.pie(df,\n",
        "             names='Disaster Type',\n",
        "             title='üåç Proportion of Disaster Types')\n",
        "\n",
        "# Save as HTML file\n",
        "fig.write_html(\"disaster_pie_chart.html\")\n",
        "\n",
        "# Download the HTML file\n",
        "files.download(\"disaster_pie_chart.html\")\n"
      ],
      "metadata": {
        "id": "G_fEAeNZ2pfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a year column if needed\n",
        "df['Start_Year'] = df['Start_Date'].dt.year\n",
        "\n",
        "# Count disasters per year\n",
        "yearly = df['Start_Year'].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.lineplot(x=yearly.index, y=yearly.values, marker='o')\n",
        "plt.title('üìÜ Disaster Frequency Over Time')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Disasters')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h7SqSePyiRvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with NaN in the column used for size\n",
        "plot_df = df.dropna(subset=[\"Total Damage, Adjusted ('000 US$)\"])\n",
        "\n",
        "fig = px.scatter_geo(plot_df,\n",
        "    lat='Latitude',\n",
        "    lon='Longitude',\n",
        "    hover_name='Disaster Type',\n",
        "    size=\"Total Damage, Adjusted ('000 US$)\",\n",
        "    color='Disaster Type',\n",
        "    projection=\"natural earth\",\n",
        "    title=\"üåê Global Map of Disasters by Damage Cost\"\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7TQG0H9WiWeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from google.colab import files\n",
        "\n",
        "# Drop rows with NaNs in the size column\n",
        "plot_df = df.dropna(subset=[\"Total Damage, Adjusted ('000 US$)\"])\n",
        "\n",
        "# Create the interactive Geo Scatter Plot\n",
        "fig = px.scatter_geo(\n",
        "    plot_df,\n",
        "    lat='Latitude',\n",
        "    lon='Longitude',\n",
        "    hover_name='Disaster Type',\n",
        "    size=\"Total Damage, Adjusted ('000 US$)\",\n",
        "    color='Disaster Type',\n",
        "    projection=\"natural earth\",\n",
        "    title=\"üåê Global Map of Disasters by Damage Cost\"\n",
        ")\n",
        "\n",
        "# Save the interactive map as an HTML file\n",
        "fig.write_html(\"global_disasters_map.html\")\n",
        "\n",
        "# Trigger download\n",
        "files.download(\"global_disasters_map.html\")\n"
      ],
      "metadata": {
        "id": "GdOcQCNE26LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with NaN in the 'Disaster_Duration' column for plotting\n",
        "plot_df = df.dropna(subset=['Disaster_Duration'])\n",
        "\n",
        "fig = px.scatter(plot_df,\n",
        "    x='Total Deaths',\n",
        "    y=\"Total Damage, Adjusted ('000 US$)\",\n",
        "    color='Disaster Type',\n",
        "    size='Disaster_Duration',\n",
        "    hover_name='Region',\n",
        "    title='üí• Damage vs. Deaths (Bubble Size = Duration)'\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "LbDj9CBMiqEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from google.colab import files\n",
        "\n",
        "# Drop rows with NaN or negative Disaster_Duration\n",
        "plot_df = df.dropna(subset=['Disaster_Duration', 'Total Deaths', \"Total Damage, Adjusted ('000 US$)\"])\n",
        "plot_df = plot_df[plot_df['Disaster_Duration'] > 0]\n",
        "\n",
        "# Create interactive scatter plot\n",
        "fig = px.scatter(\n",
        "    plot_df,\n",
        "    x='Total Deaths',\n",
        "    y=\"Total Damage, Adjusted ('000 US$)\",\n",
        "    color='Disaster Type',\n",
        "    size='Disaster_Duration',\n",
        "    hover_name='Region',\n",
        "    title='üí• Damage vs. Deaths (Bubble Size = Duration)'\n",
        ")\n",
        "\n",
        "# Save and download as HTML\n",
        "fig.write_html(\"damage_vs_deaths_bubble.html\")\n",
        "files.download(\"damage_vs_deaths_bubble.html\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PfGRnV2T3JG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows with valid aid & damage data\n",
        "aid_df = df[[\n",
        "    'Disaster Type',\n",
        "    \"AID Contribution ('000 US$)\",\n",
        "    \"Total Damage, Adjusted ('000 US$)\"\n",
        "]].dropna()\n",
        "\n",
        "aid_avg = aid_df.groupby('Disaster Type').mean().reset_index()\n",
        "\n",
        "fig = px.bar(aid_avg,\n",
        "             x='Disaster Type',\n",
        "             y=[\"AID Contribution ('000 US$)\", \"Total Damage, Adjusted ('000 US$)\"],\n",
        "             barmode='group',\n",
        "             title='üÜò Average Aid vs Damage by Disaster Type')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "UHFiSdHFjASe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from google.colab import files\n",
        "\n",
        "# Filter rows with valid aid & damage data\n",
        "aid_df = df[[\n",
        "    'Disaster Type',\n",
        "    \"AID Contribution ('000 US$)\",\n",
        "    \"Total Damage, Adjusted ('000 US$)\"\n",
        "]].dropna()\n",
        "\n",
        "# Compute average aid and damage per disaster type\n",
        "aid_avg = aid_df.groupby('Disaster Type').mean(numeric_only=True).reset_index()\n",
        "\n",
        "# Create grouped bar chart\n",
        "fig = px.bar(\n",
        "    aid_avg,\n",
        "    x='Disaster Type',\n",
        "    y=[\"AID Contribution ('000 US$)\", \"Total Damage, Adjusted ('000 US$)\"],\n",
        "    barmode='group',\n",
        "    title='üÜò Average Aid vs Damage by Disaster Type'\n",
        ")\n",
        "\n",
        "# Show interactive chart\n",
        "fig.show()\n",
        "\n",
        "# Save as interactive HTML and offer download\n",
        "fig.write_html(\"aid_vs_damage_bar.html\")\n",
        "files.download(\"aid_vs_damage_bar.html\")\n"
      ],
      "metadata": {
        "id": "YjmkG0-M3sMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# Create figure with GridSpec layout\n",
        "fig = plt.figure(constrained_layout=True, figsize=(18, 12))\n",
        "gs = gridspec.GridSpec(2, 2, figure=fig)\n",
        "\n",
        "# Plot 1: Disaster Type Count\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "sns.countplot(y='Disaster Type', data=df, order=df['Disaster Type'].value_counts().index[:10], ax=ax1)\n",
        "ax1.set_title('Top 10 Disaster Types')\n",
        "ax1.set_xlabel('Count')\n",
        "ax1.set_ylabel('Disaster Type')\n",
        "\n",
        "# Plot 2: Damage by Region (log scale)\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "sns.boxplot(\n",
        "    x='Region',\n",
        "    y=\"Total Damage, Adjusted ('000 US$)\",\n",
        "    data=df,\n",
        "    ax=ax2\n",
        ")\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_title('Total Damage by Region (Log Scale)')\n",
        "ax2.set_xlabel('Region')\n",
        "ax2.set_ylabel('Total Damage ($000)')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot 3: Deaths vs Damage Scatter\n",
        "ax3 = fig.add_subplot(gs[1, 0])\n",
        "sns.scatterplot(\n",
        "    x='Total Deaths',\n",
        "    y=\"Total Damage, Adjusted ('000 US$)\",\n",
        "    hue='Disaster Type',\n",
        "    data=df,\n",
        "    ax=ax3,\n",
        "    alpha=0.7,\n",
        "    palette='tab10',\n",
        "    legend=False\n",
        ")\n",
        "ax3.set_xscale('log')\n",
        "ax3.set_yscale('log')\n",
        "ax3.set_title('Total Deaths vs Damage (Log-Log Scale)')\n",
        "ax3.set_xlabel('Total Deaths')\n",
        "ax3.set_ylabel('Total Damage ($000)')\n",
        "\n",
        "# Plot 4: Disaster Duration Distribution\n",
        "ax4 = fig.add_subplot(gs[1, 1])\n",
        "sns.histplot(df['Disaster_Duration'], bins=30, kde=True, color='teal', ax=ax4)\n",
        "ax4.set_title('Distribution of Disaster Duration (Days)')\n",
        "ax4.set_xlabel('Duration')\n",
        "ax4.set_ylabel('Count')\n",
        "\n",
        "plt.suptitle('üåç Disaster Impact Dashboard Summary', fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "B-dgODBojHgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as PNG (must run before plt.show())\n",
        "fig.savefig(\"disaster_dashboard.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Download the file in Colab\n",
        "from google.colab import files\n",
        "files.download(\"disaster_dashboard.png\")\n"
      ],
      "metadata": {
        "id": "f_zIJbO_jKIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets\n"
      ],
      "metadata": {
        "id": "HUSmosCInWRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n"
      ],
      "metadata": {
        "id": "a4rc9bChncdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns to avoid space issues\n",
        "df.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "\n",
        "# Rename columns to make date parsing easier\n",
        "df.rename(columns={\n",
        "    'Start Year': 'Start_Year',\n",
        "    'Start Month': 'Start_Month',\n",
        "    'Start Day': 'Start_Day',\n",
        "    'End Year': 'End_Year',\n",
        "    'End Month': 'End_Month',\n",
        "    'End Day': 'End_Day'\n",
        "}, inplace=True)\n",
        "\n",
        "# Fill missing day values with 1 for parsing\n",
        "df['Start_Day'] = df['Start_Day'].fillna(1).astype(int)\n",
        "df['End_Day'] = df['End_Day'].fillna(1).astype(int)\n",
        "\n",
        "# Create Start and End Dates safely\n",
        "df['Start_Date'] = pd.to_datetime(df[['Start_Year', 'Start_Month', 'Start_Day']].rename(columns={'Start_Year': 'year', 'Start_Month': 'month', 'Start_Day': 'day'}), errors='coerce')\n",
        "df['End_Date'] = pd.to_datetime(df[['End_Year', 'End_Month', 'End_Day']].rename(columns={'End_Year': 'year', 'End_Month': 'month', 'End_Day': 'day'}), errors='coerce')\n",
        "\n",
        "# Calculate Disaster Duration\n",
        "df['Disaster_Duration'] = (df['End_Date'] - df['Start_Date']).dt.days"
      ],
      "metadata": {
        "id": "75oTXtpQn2Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Load your cleaned DataFrame (you can change this path if needed)\n",
        "# Assuming 'df' is already loaded and cleaned from previous steps.\n",
        "# If you are running this cell independently, you might need to load and clean 'df' first.\n",
        "\n",
        "# --------- Widgets for interactivity ----------\n",
        "region_selector = widgets.SelectMultiple(\n",
        "    options=df['Region'].dropna().unique(),\n",
        "    value=[],\n",
        "    description='Region:',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "type_selector = widgets.SelectMultiple(\n",
        "    options=df['Disaster Type'].dropna().unique(),\n",
        "    value=[],\n",
        "    description='Type:',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "def filter_df(region_vals, type_vals):\n",
        "    filtered = df.copy()\n",
        "    if region_vals:\n",
        "        filtered = filtered[filtered['Region'].isin(region_vals)]\n",
        "    if type_vals:\n",
        "        filtered = filtered[filtered['Disaster Type'].isin(type_vals)]\n",
        "    return filtered\n",
        "\n",
        "# --------- Plotting Function --------------\n",
        "def plot_dashboard(region_vals, type_vals):\n",
        "    filtered_df = filter_df(region_vals, type_vals)\n",
        "\n",
        "    plt.figure(figsize=(20, 16))\n",
        "\n",
        "    # 1. Top Disaster Types\n",
        "    plt.subplot(2, 2, 1)\n",
        "    if not filtered_df.empty:\n",
        "        top_types = filtered_df['Disaster Type'].value_counts().nlargest(10)\n",
        "        sns.barplot(x=top_types.values, y=top_types.index, palette=\"magma\")\n",
        "        plt.title(\"Top 10 Disaster Types\")\n",
        "        plt.xlabel(\"Number of Events\")\n",
        "        plt.ylabel(\"Disaster Type\")\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, \"No data for selection\", ha='center', va='center')\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "    # 2. Damage by Region\n",
        "    plt.subplot(2, 2, 2)\n",
        "    # Check if 'Total Damage, Adjusted ('000 US$)' exists and is not all NaN in filtered_df\n",
        "    if \"Total Damage, Adjusted ('000 US$)\" in filtered_df.columns and not filtered_df[\"Total Damage, Adjusted ('000 US$)\"].dropna().empty:\n",
        "        sns.boxplot(\n",
        "            x='Region',\n",
        "            y=\"Total Damage, Adjusted ('000 US$)\",\n",
        "            data=filtered_df,\n",
        "            showfliers=False\n",
        "        )\n",
        "        plt.yscale(\"log\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.title(\"Damage by Region (log scale)\")\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, \"No damage data for selection\", ha='center', va='center')\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "    # 3. Deaths vs Damage (scatter)\n",
        "    plt.subplot(2, 2, 3)\n",
        "    # Check if necessary columns exist and have data for scatter plot\n",
        "    scatter_cols = ['Total Deaths', \"Total Damage, Adjusted ('000 US$)\", 'Disaster Type']\n",
        "    if all(col in filtered_df.columns for col in scatter_cols) and not filtered_df[scatter_cols].dropna().empty:\n",
        "        sns.scatterplot(\n",
        "            x='Total Deaths',\n",
        "            y=\"Total Damage, Adjusted ('000 US$)\",\n",
        "            hue='Disaster Type',\n",
        "            data=filtered_df,\n",
        "            alpha=0.6,\n",
        "            legend=False\n",
        "        )\n",
        "        plt.xscale(\"log\")\n",
        "        plt.yscale(\"log\")\n",
        "        plt.title(\"Deaths vs. Damage\")\n",
        "        plt.xlabel(\"Total Deaths (log)\")\n",
        "        plt.ylabel(\"Damage (log)\")\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, \"No death or damage data for selection\", ha='center', va='center')\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "    # 4. Duration Distribution\n",
        "    plt.subplot(2, 2, 4)\n",
        "    if 'Disaster_Duration' in filtered_df.columns and not filtered_df['Disaster_Duration'].dropna().empty:\n",
        "        sns.histplot(filtered_df['Disaster_Duration'].dropna(), bins=30, kde=True, color='steelblue')\n",
        "        plt.title(\"Disaster Duration Distribution (days)\")\n",
        "        plt.xlabel(\"Duration (Days)\")\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, \"No duration data for selection\", ha='center', va='center')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --------- Interactive Widget UI ------------\n",
        "interactive_plot = widgets.interactive_output(\n",
        "    plot_dashboard,\n",
        "    {'region_vals': region_selector, 'type_vals': type_selector}\n",
        ")\n",
        "\n",
        "dashboard_box = widgets.HBox([region_selector, type_selector])\n",
        "display(dashboard_box, interactive_plot)"
      ],
      "metadata": {
        "id": "SSAA3lpyniTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive if you want to save it there\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Get the current notebook's path manually if needed\n",
        "notebook_path = '/content/your_notebook_name.ipynb'  # Replace with actual name if you saved it\n",
        "\n",
        "# Export the current notebook to file\n",
        "!jupyter nbconvert --to notebook --output=\"cleaned_notebook.ipynb\" --ClearMetadataPreprocessor.enabled=True --ClearOutputPreprocessor.enabled=True \"your_notebook_name.ipynb\"\n",
        "\n",
        "print(\"Cleaned notebook saved as 'cleaned_notebook.ipynb'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FvYPOJZdnPfB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}